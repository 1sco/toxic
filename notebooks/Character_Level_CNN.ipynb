{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "pip3 install torchtext\n",
    "pip3 install http://download.pytorch.org/whl/cu90/torch-0.3.1-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, accuracy_score,\n",
    "                             roc_auc_score)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/abs/1509.01626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm = tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('..', 'data')\n",
    "train_path = Path(data_path, 'train.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "train_df['comment_text'] = train_df['comment_text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = Path(data_path, 'test.csv')\n",
    "\n",
    "test_df = pd.read_csv(test_path)\n",
    "submission = pd.DataFrame({'id': test_df['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1,\n",
    "                                    random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    143613.000000\n",
       "mean        394.748811\n",
       "std         592.753457\n",
       "min           6.000000\n",
       "25%          96.000000\n",
       "50%         206.000000\n",
       "75%         436.000000\n",
       "max        5000.000000\n",
       "Name: comment_text, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['comment_text'].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_examples(df: pd.DataFrame, fields):\n",
    "    fields = {field_name: (field_name, field)\n",
    "                       for field_name, field in fields.items()}\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        example = data.Example.fromdict(row, fields)\n",
    "        yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f991dae35aaf4f4bacca43aab5852577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecbb8fc4f474ad8b5131d94c381ae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_len = 5000\n",
    "text_field = data.Field(tokenize=(lambda s: list(s)), batch_first=True,\n",
    "                       fix_length=max_len)\n",
    "label_field = data.Field(sequential=False, use_vocab=False,\n",
    "                         tensor_type=torch.FloatTensor)\n",
    "\n",
    "fields = OrderedDict({'comment_text': text_field, 'toxic': label_field,\n",
    "                      'severe_toxic': label_field, 'obscene': label_field,\n",
    "                      'threat': label_field, 'insult': label_field,\n",
    "                      'identity_hate': label_field})\n",
    "\n",
    "\n",
    "train_examples = list(make_train_examples(train_df, fields))\n",
    "val_examples = list(make_train_examples(val_df, fields))\n",
    "test_examples = list(make_train_examples(test_df, fields))\n",
    "\n",
    "train_set = data.Dataset(train_examples, fields)\n",
    "val_set = data.Dataset(val_examples, fields)\n",
    "test_set = data.Dataset(test_examples, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, n_classes=6, dropout=0.1):\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(vocab_size, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )            \n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(46336, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(1024, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        # collapse\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # linear layer\n",
    "        x = self.fc1(x)\n",
    "        # linear layer\n",
    "        x = self.fc2(x)\n",
    "        # linear layer\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fields = ['toxic', 'severe_toxic', 'obscene',\n",
    "                'threat', 'insult', 'identity_hate']\n",
    "char_cnn = CharCNN(len(text_field.vocab), n_classes=len(label_fields))\n",
    "char_cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2278"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y, n_dims=None):\n",
    "    \"\"\" Take integer y (tensor or variable) with n dims and convert it to 1-hot representation with n+1 dims. \"\"\"\n",
    "    y_tensor = y.data if isinstance(y, Variable) else y\n",
    "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
    "    y_one_hot = torch.zeros(y_tensor.size()[0], n_dims).scatter_(1, y_tensor, 1)\n",
    "    y_one_hot = y_one_hot.view(y.shape[0], n_dims, -1)\n",
    "    return Variable(y_one_hot) if isinstance(y, Variable) else y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de9d779e8254a92ab573163977fd385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "input_name = 'comment_text'\n",
    "label_names = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "               'insult', 'identity_hate']\n",
    "\n",
    "batches_train, batches_val = data.BucketIterator.splits(\n",
    "    (train_set, val_set), batch_size=batch_size, repeat=False,\n",
    "    sort_key=lambda x: len(getattr(x, input_name)))\n",
    "\n",
    "batches_test = data.BucketIterator(dataset=test_set, batch_size=batch_size,\n",
    "                                   sort_key=lambda x: len(getattr(x, input_name)))\n",
    "\n",
    "optimizer = optim.Adam(char_cnn.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(n_epochs):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for n, batch in enumerate(tqdm(batches_train)):\n",
    "        # get the inputs\n",
    "        inputs = getattr(batch, input_name)\n",
    "        inputs = to_one_hot(inputs, n_dims=len(text_field.vocab))\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = char_cnn(inputs)\n",
    "        losses = []\n",
    "    \n",
    "        # get all output fields and their losses\n",
    "        # and backprop for each of them\n",
    "        for i, label_name in enumerate(label_names):\n",
    "            targets = getattr(batch, label_name)\n",
    "            label_outputs = outputs[:, i]\n",
    "            loss = criterion(label_outputs, targets)\n",
    "            losses.append(loss)\n",
    "        \n",
    "        total_loss = sum(losses)\n",
    "        total_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += total_loss.data[0]\n",
    "        if n % 100 == 99:    # print every 1000 mini-batches\n",
    "            print('[{}, {}] loss: {:.3f}'.format(epoch + 1,\n",
    "                                                n + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print = __builtins__.print\n",
    "\n",
    "def get_preds_val(net, val_iter, *, input_name, label_names):\n",
    "    net.eval()\n",
    "    \n",
    "    y_labels = defaultdict(list)\n",
    "    scores_labels = defaultdict(list)\n",
    "    \n",
    "    for batch in tqdm(val_iter):\n",
    "        X = getattr(batch, input_name)\n",
    "        iX = to_one_hot(inputs, n_dims=len(text_field.vocab))\n",
    "        out = net(X)\n",
    "        out_probas = F.sigmoid(out)\n",
    "        \n",
    "        # put label dimension first\n",
    "        # so we can iterate over each label's predictions\n",
    "        out_probas = out_probas.permute(1, 0)\n",
    "        \n",
    "        for n, (label_name, label_probas) in enumerate(zip(label_names, out_probas)):\n",
    "            y_true = getattr(batch, label_name).data.cpu().numpy()\n",
    "            label_probas = label_probas.data.cpu().numpy()\n",
    "            assert len(y_true) == len(label_probas)\n",
    "            \n",
    "            y_labels[label_name].append(y_true)\n",
    "            scores_labels[label_name].append(label_probas)\n",
    "    \n",
    "    for label_name in label_names:\n",
    "        y_labels[label_name] = np.hstack(y_labels[label_name])\n",
    "        scores_labels[label_name] = np.hstack(scores_labels[label_name])\n",
    "    \n",
    "    return y_labels, scores_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels, scores_labels = get_preds_val(char_cnn, batches_val,\n",
    "                                        input_name=input_name,\n",
    "                                        label_names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for label_name in label_names:\n",
    "    true_labels = y_labels[label_name]\n",
    "    scores = scores_labels[label_name]\n",
    "    score = roc_auc_score(true_labels, scores)\n",
    "    roc_scores.append(score)\n",
    "    print(label_name, score)\n",
    "\n",
    "print()\n",
    "mean_roc = np.mean(roc_scores)\n",
    "print(f'Mean ROC {mean_roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, scores_test_labels = get_preds_val(char_cnn, batches_test,\n",
    "                                        input_name=input_name,\n",
    "                                        label_names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_name in label_names:\n",
    "    submission[label_name] = scores_test_labels[label_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('char_cnn_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
